{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:05:26.174916Z",
     "start_time": "2018-11-27T15:05:26.151988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application to FACT Data and Boosting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"tocheading\">Table of Contents</h2>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The story so far:\n",
    "\n",
    "- Linear Discriminant Analysis (LDA) and Fisher's linear discriminant\n",
    "- Principal Component Analysis (PCA)\n",
    "- Feature Selection\n",
    "- Supervised Learning\n",
    "- Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:05:27.643365Z",
     "start_time": "2018-11-27T15:05:26.177785Z"
    }
   },
   "outputs": [],
   "source": [
    "from ml import plots\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:05:27.643365Z",
     "start_time": "2018-11-27T15:05:26.177785Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "plots.set_plot_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Complete Example\n",
    "\n",
    "Below we load a dataset containing data observed by the FACT telescope.\n",
    "\n",
    "<img width=\"45%\" src=\"http://www.miguelclaro.com/wp/wp-content/uploads/2013/10/FACTMilkyWayVertical-4650-net.jpg\" />   \n",
    "\n",
    "We will perform the typical steps to build and evaluate a classifier.\n",
    "\n",
    "0. Understand where your data comes from\n",
    "\n",
    "1. Preprocessing\n",
    "    * Drop Constant Values,\n",
    "    * Handle Missing Data \n",
    "    * Feature Generation\n",
    "\n",
    "2. Splitting\n",
    "    \n",
    "    * Split your data into training and evaluation sets\n",
    "    \n",
    "3. Training \n",
    "    \n",
    "    * Train your classifier of choice.\n",
    "    \n",
    "4. Evaluation\n",
    "    \n",
    "    * Evaluate the performance on the test data set.\n",
    "    * If not good enough, go back to step 1 \n",
    "    \n",
    "5. Physics\n",
    "    \n",
    "    * Check whether your data support your hypothesis\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get to know your data\n",
    "\n",
    "Cherenkov telescopes record short flashes of light produced by very high energy cosmic rays and photons hitting earths atmosphere.\n",
    "\n",
    "![](https://www.cta-observatory.org/wp-content/uploads/2016/05/cta47.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:00.589316Z",
     "start_time": "2018-11-27T15:07:00.584438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- https://nextcloud.e5.physik.tu-dortmund.de/index.php/s/e7yb2mifGDeyDBN/download -->\n",
       "<video width=\"100%\" controls>\n",
       "  <source src=\"./resources/fact_events.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<!-- https://nextcloud.e5.physik.tu-dortmund.de/index.php/s/e7yb2mifGDeyDBN/download -->\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"./resources/fact_events.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use machine learning for two tasks in this example. \n",
    "\n",
    " * Train a classifier to distinguish events induced by gamma rays form events induced by cosmic rays\n",
    " * Train a regressor to estimate the energy of the incoming primary particle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess data\n",
    "\n",
    "A lot of preprocessing has already happened at this point.\n",
    "\n",
    "* Calibration of Raw Data\n",
    "* Data Reduction from voltage timeseries per pixel to #photons and mean time for each pixel\n",
    "* Calculation of image features\n",
    "\n",
    "\n",
    "Load data and remove unwanted columns and store the true labels separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:01.600004Z",
     "start_time": "2018-11-27T15:07:00.592824Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fact.io import read_h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:02.004702Z",
     "start_time": "2018-11-27T15:07:01.603010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_time_mean</th>\n",
       "      <th>arrival_time_pedestal_kurtosis</th>\n",
       "      <th>arrival_time_pedestal_max</th>\n",
       "      <th>arrival_time_pedestal_mean</th>\n",
       "      <th>arrival_time_pedestal_median</th>\n",
       "      <th>arrival_time_pedestal_min</th>\n",
       "      <th>arrival_time_pedestal_p25</th>\n",
       "      <th>arrival_time_pedestal_p75</th>\n",
       "      <th>arrival_time_pedestal_skewness</th>\n",
       "      <th>arrival_time_pedestal_variance</th>\n",
       "      <th>...</th>\n",
       "      <th>time_gradient_slope_long</th>\n",
       "      <th>time_gradient_slope_long_err</th>\n",
       "      <th>time_gradient_slope_trans</th>\n",
       "      <th>time_gradient_slope_trans_err</th>\n",
       "      <th>time_gradient_sse_long</th>\n",
       "      <th>time_gradient_sse_trans</th>\n",
       "      <th>timespread</th>\n",
       "      <th>timespread_weighted</th>\n",
       "      <th>trigger_type</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.064510</td>\n",
       "      <td>-1.109841</td>\n",
       "      <td>96.251409</td>\n",
       "      <td>50.056320</td>\n",
       "      <td>48.541463</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.315271</td>\n",
       "      <td>70.190476</td>\n",
       "      <td>0.122054</td>\n",
       "      <td>548.930450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028107</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.184584</td>\n",
       "      <td>0.033308</td>\n",
       "      <td>3.345592</td>\n",
       "      <td>0.312691</td>\n",
       "      <td>0.838293</td>\n",
       "      <td>0.665250</td>\n",
       "      <td>4</td>\n",
       "      <td>4.125594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.971349</td>\n",
       "      <td>-1.081534</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>49.938162</td>\n",
       "      <td>49.299742</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.720019</td>\n",
       "      <td>69.295873</td>\n",
       "      <td>0.100216</td>\n",
       "      <td>539.360854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005743</td>\n",
       "      <td>0.039438</td>\n",
       "      <td>0.021480</td>\n",
       "      <td>0.066726</td>\n",
       "      <td>3.880951</td>\n",
       "      <td>3.818274</td>\n",
       "      <td>0.746172</td>\n",
       "      <td>0.802401</td>\n",
       "      <td>4</td>\n",
       "      <td>5.008837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.364374</td>\n",
       "      <td>-1.137693</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>50.406649</td>\n",
       "      <td>48.931727</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.915493</td>\n",
       "      <td>70.418605</td>\n",
       "      <td>0.144873</td>\n",
       "      <td>558.159445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025479</td>\n",
       "      <td>0.034733</td>\n",
       "      <td>-0.046940</td>\n",
       "      <td>0.051830</td>\n",
       "      <td>6.143687</td>\n",
       "      <td>5.922080</td>\n",
       "      <td>0.857385</td>\n",
       "      <td>0.695980</td>\n",
       "      <td>4</td>\n",
       "      <td>5.713048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.754275</td>\n",
       "      <td>-1.088434</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>49.789320</td>\n",
       "      <td>47.707045</td>\n",
       "      <td>6.176471</td>\n",
       "      <td>31.011719</td>\n",
       "      <td>69.293104</td>\n",
       "      <td>0.153315</td>\n",
       "      <td>539.759137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065316</td>\n",
       "      <td>0.047992</td>\n",
       "      <td>0.144199</td>\n",
       "      <td>0.099693</td>\n",
       "      <td>3.735585</td>\n",
       "      <td>3.588492</td>\n",
       "      <td>0.954412</td>\n",
       "      <td>0.912319</td>\n",
       "      <td>4</td>\n",
       "      <td>4.236660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.341319</td>\n",
       "      <td>-1.133003</td>\n",
       "      <td>98.207941</td>\n",
       "      <td>49.314529</td>\n",
       "      <td>47.447368</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>29.168577</td>\n",
       "      <td>69.760411</td>\n",
       "      <td>0.154019</td>\n",
       "      <td>560.212447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004945</td>\n",
       "      <td>0.109799</td>\n",
       "      <td>0.277320</td>\n",
       "      <td>0.135065</td>\n",
       "      <td>124.030428</td>\n",
       "      <td>84.484591</td>\n",
       "      <td>3.358279</td>\n",
       "      <td>2.771534</td>\n",
       "      <td>4</td>\n",
       "      <td>6.694258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   arrival_time_mean  arrival_time_pedestal_kurtosis  \\\n",
       "0          50.064510                       -1.109841   \n",
       "1          49.971349                       -1.081534   \n",
       "2          50.364374                       -1.137693   \n",
       "3          49.754275                       -1.088434   \n",
       "4          49.341319                       -1.133003   \n",
       "\n",
       "   arrival_time_pedestal_max  arrival_time_pedestal_mean  \\\n",
       "0                  96.251409                   50.056320   \n",
       "1                  99.000000                   49.938162   \n",
       "2                  99.000000                   50.406649   \n",
       "3                  98.000000                   49.789320   \n",
       "4                  98.207941                   49.314529   \n",
       "\n",
       "   arrival_time_pedestal_median  arrival_time_pedestal_min  \\\n",
       "0                     48.541463                   5.000000   \n",
       "1                     49.299742                   5.000000   \n",
       "2                     48.931727                   5.000000   \n",
       "3                     47.707045                   6.176471   \n",
       "4                     47.447368                   5.000000   \n",
       "\n",
       "   arrival_time_pedestal_p25  arrival_time_pedestal_p75  \\\n",
       "0                  30.315271                  70.190476   \n",
       "1                  30.720019                  69.295873   \n",
       "2                  30.915493                  70.418605   \n",
       "3                  31.011719                  69.293104   \n",
       "4                  29.168577                  69.760411   \n",
       "\n",
       "   arrival_time_pedestal_skewness  arrival_time_pedestal_variance  ...  \\\n",
       "0                        0.122054                      548.930450  ...   \n",
       "1                        0.100216                      539.360854  ...   \n",
       "2                        0.144873                      558.159445  ...   \n",
       "3                        0.153315                      539.759137  ...   \n",
       "4                        0.154019                      560.212447  ...   \n",
       "\n",
       "   time_gradient_slope_long  time_gradient_slope_long_err  \\\n",
       "0                 -0.028107                      0.072398   \n",
       "1                 -0.005743                      0.039438   \n",
       "2                 -0.025479                      0.034733   \n",
       "3                  0.065316                      0.047992   \n",
       "4                 -0.004945                      0.109799   \n",
       "\n",
       "   time_gradient_slope_trans  time_gradient_slope_trans_err  \\\n",
       "0                   0.184584                       0.033308   \n",
       "1                   0.021480                       0.066726   \n",
       "2                  -0.046940                       0.051830   \n",
       "3                   0.144199                       0.099693   \n",
       "4                   0.277320                       0.135065   \n",
       "\n",
       "   time_gradient_sse_long  time_gradient_sse_trans  timespread  \\\n",
       "0                3.345592                 0.312691    0.838293   \n",
       "1                3.880951                 3.818274    0.746172   \n",
       "2                6.143687                 5.922080    0.857385   \n",
       "3                3.735585                 3.588492    0.954412   \n",
       "4              124.030428                84.484591    3.358279   \n",
       "\n",
       "   timespread_weighted  trigger_type     width  \n",
       "0             0.665250             4  4.125594  \n",
       "1             0.802401             4  5.008837  \n",
       "2             0.695980             4  5.713048  \n",
       "3             0.912319             4  4.236660  \n",
       "4             2.771534             4  6.694258  \n",
       "\n",
       "[5 rows x 262 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gammas = read_h5py('./resources/sample_diffuse_gammas.h5', key='events')\n",
    "gammas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now delete all simulated values which can not be observed during measurement in the physical world. We know which columns to remove because they have a special prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:02.055025Z",
     "start_time": "2018-11-27T15:07:02.007914Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forbidden_columns = 'ceres_|mc_|corsika_|run_|source_position_|pointing_|aux_|event_num|incident_angle|.*pedestal|fluct_|ped_'\n",
    "gammas = gammas.filter(regex=f'^(?!{forbidden_columns}).*$')\n",
    "\n",
    "len(gammas.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data types of the columns. We can select non-numeric types and encode them. But in this case we might as well drop them as the attribute is not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:02.075296Z",
     "start_time": "2018-11-27T15:07:02.057255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['runtype'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "c = gammas.select_dtypes(exclude=['number']).columns\n",
    "print(c)\n",
    "\n",
    "gammas = gammas.drop(c, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can spot the columns with constant values by looking at the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:02.529060Z",
     "start_time": "2018-11-27T15:07:02.078743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_time_mean</th>\n",
       "      <th>arrival_time_shower_kurtosis</th>\n",
       "      <th>arrival_time_shower_max</th>\n",
       "      <th>arrival_time_shower_mean</th>\n",
       "      <th>arrival_time_shower_min</th>\n",
       "      <th>arrival_time_shower_skewness</th>\n",
       "      <th>arrival_time_shower_variance</th>\n",
       "      <th>cog_x</th>\n",
       "      <th>cog_y</th>\n",
       "      <th>concentration_cog</th>\n",
       "      <th>...</th>\n",
       "      <th>time_gradient_slope_long</th>\n",
       "      <th>time_gradient_slope_long_err</th>\n",
       "      <th>time_gradient_slope_trans</th>\n",
       "      <th>time_gradient_slope_trans_err</th>\n",
       "      <th>time_gradient_sse_long</th>\n",
       "      <th>time_gradient_sse_trans</th>\n",
       "      <th>timespread</th>\n",
       "      <th>timespread_weighted</th>\n",
       "      <th>trigger_type</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.740845</td>\n",
       "      <td>1.669750</td>\n",
       "      <td>54.761202</td>\n",
       "      <td>51.848245</td>\n",
       "      <td>49.116457</td>\n",
       "      <td>0.084997</td>\n",
       "      <td>3.003343</td>\n",
       "      <td>1.319683</td>\n",
       "      <td>-14.999594</td>\n",
       "      <td>0.341442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.036415</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.071118</td>\n",
       "      <td>32.358447</td>\n",
       "      <td>66.361993</td>\n",
       "      <td>1.443372</td>\n",
       "      <td>1.273125</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.504231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.765677</td>\n",
       "      <td>3.260473</td>\n",
       "      <td>4.513202</td>\n",
       "      <td>2.979274</td>\n",
       "      <td>2.996825</td>\n",
       "      <td>1.185409</td>\n",
       "      <td>5.509836</td>\n",
       "      <td>84.890029</td>\n",
       "      <td>87.004145</td>\n",
       "      <td>0.175294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068504</td>\n",
       "      <td>0.034970</td>\n",
       "      <td>0.100130</td>\n",
       "      <td>0.061352</td>\n",
       "      <td>56.183769</td>\n",
       "      <td>344.951531</td>\n",
       "      <td>0.817965</td>\n",
       "      <td>0.740511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.755483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>47.316001</td>\n",
       "      <td>-3.308731</td>\n",
       "      <td>41.170213</td>\n",
       "      <td>39.042000</td>\n",
       "      <td>35.359862</td>\n",
       "      <td>-4.533000</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>-175.398979</td>\n",
       "      <td>-178.151067</td>\n",
       "      <td>-0.030815</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.491409</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>-0.790551</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.028250</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.126072</td>\n",
       "      <td>0.131271</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.064943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.241067</td>\n",
       "      <td>-0.469649</td>\n",
       "      <td>51.888632</td>\n",
       "      <td>50.060331</td>\n",
       "      <td>47.572560</td>\n",
       "      <td>-0.593028</td>\n",
       "      <td>0.955858</td>\n",
       "      <td>-65.547247</td>\n",
       "      <td>-86.870373</td>\n",
       "      <td>0.202670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033493</td>\n",
       "      <td>0.014003</td>\n",
       "      <td>-0.041412</td>\n",
       "      <td>0.033228</td>\n",
       "      <td>6.641634</td>\n",
       "      <td>7.048601</td>\n",
       "      <td>0.928098</td>\n",
       "      <td>0.828031</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.223795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.706151</td>\n",
       "      <td>0.717916</td>\n",
       "      <td>54.027215</td>\n",
       "      <td>51.734115</td>\n",
       "      <td>49.356218</td>\n",
       "      <td>0.124951</td>\n",
       "      <td>1.700814</td>\n",
       "      <td>1.397124</td>\n",
       "      <td>-21.136853</td>\n",
       "      <td>0.300876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.026125</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.053872</td>\n",
       "      <td>15.690777</td>\n",
       "      <td>17.889471</td>\n",
       "      <td>1.243882</td>\n",
       "      <td>1.093557</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.296922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.178076</td>\n",
       "      <td>2.785657</td>\n",
       "      <td>56.886122</td>\n",
       "      <td>53.624683</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.777732</td>\n",
       "      <td>3.255480</td>\n",
       "      <td>68.424271</td>\n",
       "      <td>53.570215</td>\n",
       "      <td>0.467830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034840</td>\n",
       "      <td>0.046479</td>\n",
       "      <td>0.043885</td>\n",
       "      <td>0.088357</td>\n",
       "      <td>37.561407</td>\n",
       "      <td>45.605035</td>\n",
       "      <td>1.728471</td>\n",
       "      <td>1.499146</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.616817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58.051201</td>\n",
       "      <td>26.580277</td>\n",
       "      <td>91.434777</td>\n",
       "      <td>68.149130</td>\n",
       "      <td>60.483146</td>\n",
       "      <td>4.392427</td>\n",
       "      <td>200.727871</td>\n",
       "      <td>179.151919</td>\n",
       "      <td>173.541225</td>\n",
       "      <td>0.839026</td>\n",
       "      <td>...</td>\n",
       "      <td>1.187848</td>\n",
       "      <td>0.387313</td>\n",
       "      <td>0.853158</td>\n",
       "      <td>1.387731</td>\n",
       "      <td>1944.673229</td>\n",
       "      <td>13904.011576</td>\n",
       "      <td>13.357574</td>\n",
       "      <td>13.135994</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.411963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       arrival_time_mean  arrival_time_shower_kurtosis  \\\n",
       "count       10000.000000                  10000.000000   \n",
       "mean           49.740845                      1.669750   \n",
       "std             0.765677                      3.260473   \n",
       "min            47.316001                     -3.308731   \n",
       "25%            49.241067                     -0.469649   \n",
       "50%            49.706151                      0.717916   \n",
       "75%            50.178076                      2.785657   \n",
       "max            58.051201                     26.580277   \n",
       "\n",
       "       arrival_time_shower_max  arrival_time_shower_mean  \\\n",
       "count             10000.000000              10000.000000   \n",
       "mean                 54.761202                 51.848245   \n",
       "std                   4.513202                  2.979274   \n",
       "min                  41.170213                 39.042000   \n",
       "25%                  51.888632                 50.060331   \n",
       "50%                  54.027215                 51.734115   \n",
       "75%                  56.886122                 53.624683   \n",
       "max                  91.434777                 68.149130   \n",
       "\n",
       "       arrival_time_shower_min  arrival_time_shower_skewness  \\\n",
       "count             10000.000000                  10000.000000   \n",
       "mean                 49.116457                      0.084997   \n",
       "std                   2.996825                      1.185409   \n",
       "min                  35.359862                     -4.533000   \n",
       "25%                  47.572560                     -0.593028   \n",
       "50%                  49.356218                      0.124951   \n",
       "75%                  51.000000                      0.777732   \n",
       "max                  60.483146                      4.392427   \n",
       "\n",
       "       arrival_time_shower_variance         cog_x         cog_y  \\\n",
       "count                  10000.000000  10000.000000  10000.000000   \n",
       "mean                       3.003343      1.319683    -14.999594   \n",
       "std                        5.509836     84.890029     87.004145   \n",
       "min                        0.019868   -175.398979   -178.151067   \n",
       "25%                        0.955858    -65.547247    -86.870373   \n",
       "50%                        1.700814      1.397124    -21.136853   \n",
       "75%                        3.255480     68.424271     53.570215   \n",
       "max                      200.727871    179.151919    173.541225   \n",
       "\n",
       "       concentration_cog  ...  time_gradient_slope_long  \\\n",
       "count       10000.000000  ...              10000.000000   \n",
       "mean            0.341442  ...                  0.001122   \n",
       "std             0.175294  ...                  0.068504   \n",
       "min            -0.030815  ...                 -0.491409   \n",
       "25%             0.202670  ...                 -0.033493   \n",
       "50%             0.300876  ...                  0.001012   \n",
       "75%             0.467830  ...                  0.034840   \n",
       "max             0.839026  ...                  1.187848   \n",
       "\n",
       "       time_gradient_slope_long_err  time_gradient_slope_trans  \\\n",
       "count                  10000.000000               10000.000000   \n",
       "mean                       0.036415                   0.001657   \n",
       "std                        0.034970                   0.100130   \n",
       "min                        0.000947                  -0.790551   \n",
       "25%                        0.014003                  -0.041412   \n",
       "50%                        0.026125                   0.002579   \n",
       "75%                        0.046479                   0.043885   \n",
       "max                        0.387313                   0.853158   \n",
       "\n",
       "       time_gradient_slope_trans_err  time_gradient_sse_long  \\\n",
       "count                   10000.000000            10000.000000   \n",
       "mean                        0.071118               32.358447   \n",
       "std                         0.061352               56.183769   \n",
       "min                         0.002228                0.028250   \n",
       "25%                         0.033228                6.641634   \n",
       "50%                         0.053872               15.690777   \n",
       "75%                         0.088357               37.561407   \n",
       "max                         1.387731             1944.673229   \n",
       "\n",
       "       time_gradient_sse_trans    timespread  timespread_weighted  \\\n",
       "count             10000.000000  10000.000000         10000.000000   \n",
       "mean                 66.361993      1.443372             1.273125   \n",
       "std                 344.951531      0.817965             0.740511   \n",
       "min                   0.027688      0.126072             0.131271   \n",
       "25%                   7.048601      0.928098             0.828031   \n",
       "50%                  17.889471      1.243882             1.093557   \n",
       "75%                  45.605035      1.728471             1.499146   \n",
       "max               13904.011576     13.357574            13.135994   \n",
       "\n",
       "       trigger_type         width  \n",
       "count       10000.0  10000.000000  \n",
       "mean            4.0      6.504231  \n",
       "std             0.0      1.755483  \n",
       "min             4.0      2.064943  \n",
       "25%             4.0      5.223795  \n",
       "50%             4.0      6.296922  \n",
       "75%             4.0      7.616817  \n",
       "max             4.0     28.411963  \n",
       "\n",
       "[8 rows x 62 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = gammas.describe()\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:02.547778Z",
     "start_time": "2018-11-27T15:07:02.532415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['num_pixel', 'roi', 'trigger_type'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "c = desc.columns[desc.loc['std'] == 0]\n",
    "print(c)\n",
    "gammas = gammas.drop(c, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing data. (Just delete it in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:02.594941Z",
     "start_time": "2018-11-27T15:07:02.551401Z"
    }
   },
   "outputs": [],
   "source": [
    "gammas = gammas.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we only loaded simulated gamma-ray showers. Now we do the same for the cosmic ray events. We create a method to perform all preprocessing in one step. We need this several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:02.608429Z",
     "start_time": "2018-11-27T15:07:02.597366Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.filter(regex=f'^(?!{forbidden_columns}).*$')\n",
    "    c = df.select_dtypes(exclude=['number']).columns\n",
    "    df = df.drop(c, axis='columns')\n",
    "    desc = df.describe()\n",
    "    c = desc.columns[desc.loc['std'] == 0]\n",
    "    df = df.drop(c, axis='columns')\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:03.467654Z",
     "start_time": "2018-11-27T15:07:02.611649Z"
    }
   },
   "outputs": [],
   "source": [
    "protons = read_h5py('./resources/sample_proton.h5', key='events')\n",
    "protons = preprocess(protons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform feature generation. We use our expert knowledge or intuition to create a new feature by combining existing columns into a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:03.481076Z",
     "start_time": "2018-11-27T15:07:03.471131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       18.606696\n",
       "1       21.858272\n",
       "2       39.078776\n",
       "3       13.730881\n",
       "4       29.674442\n",
       "          ...    \n",
       "9995    20.295848\n",
       "9996    19.856191\n",
       "9997    36.360764\n",
       "9998    16.875930\n",
       "9999    75.253902\n",
       "Name: awesome_feature, Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_generation(df):\n",
    "    df['awesome_feature'] =  df['size'] * (df['width'] / df['length'])\n",
    "    return df\n",
    "\n",
    "gammas = feature_generation(gammas)\n",
    "protons = feature_generation(protons)\n",
    "\n",
    "gammas['awesome_feature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look at the data so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:03.829801Z",
     "start_time": "2018-11-27T15:07:03.484278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06edd22dda8416ba44932fee5a457bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0, 70, 100)\n",
    "# bins = np.logspace(0, 5, 100)\n",
    "# bins = 100\n",
    "\n",
    "col = 'length'\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(gammas[col], bins=bins, histtype='step', lw=2, label='Gammas')\n",
    "plt.hist(protons[col], bins=bins, histtype='step', lw=2, label='Protons')\n",
    "# plt.xscale('log')\n",
    "plt.legend()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we combine the two datasets into one big matrix and build a label vector $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:03.895879Z",
     "start_time": "2018-11-27T15:07:03.832960Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.concat([gammas, protons])\n",
    "y = np.concatenate([np.ones(len(gammas)), np.zeros(len(protons))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Data\n",
    "\n",
    "Now we can split the data into test and training sets. Scikit-Learn provides some neat methods to do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:07:03.983514Z",
     "start_time": "2018-11-27T15:07:03.898708Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_test, X_train, y_test, y_train = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the classifier\n",
    "\n",
    "Now we can train any classifier we want on the prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:13:04.181685Z",
     "start_time": "2018-11-27T15:13:02.875532Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "rf = DecisionTreeClassifier(max_depth=15, criterion='entropy')\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = rf.predict(X_test)\n",
    "y_prediction_proba = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation \n",
    "\n",
    "Check accuracy of the models and other metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f24bd58b36846bcbff6acca09ed59ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.Series(rf.feature_importances_, index=gammas.columns)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "importance.sort_values().tail(20).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:13:04.199205Z",
     "start_time": "2018-11-27T15:13:04.183884Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "acc = accuracy_score(y_test, y_prediction)\n",
    "auc = roc_auc_score(y_test, y_prediction_proba[:, 1])\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prediction_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:13:46.845086Z",
     "start_time": "2018-11-27T15:13:46.501506Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644be3c486d04a69b40a95cae5b4b34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.scatter(fpr, tpr, c=thresholds, vmax=1)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.gca().set_aspect(1)\n",
    "plt.plot(fpr, tpr, '--', color='gray', alpha=0.5)\n",
    "plt.text(0.5, 0.5, f'AuC ROC: {auc:0.03f} \\nAccuracy: {acc:0.03f}')\n",
    "plt.colorbar()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform steps 3, 4, and 5 in one step using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:08:28.709336Z",
     "start_time": "2018-11-27T15:08:03.738680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.33849788, 1.28981209, 1.30354881, 1.29822016, 1.29255605]),\n",
       " 'score_time': array([0.01068687, 0.00917387, 0.00890326, 0.00941944, 0.00946593]),\n",
       " 'test_acc': array([0.66775, 0.6745 , 0.639  , 0.67   , 0.66325]),\n",
       " 'train_acc': array([0.801    , 0.7945   , 0.797125 , 0.7893125, 0.7855   ]),\n",
       " 'test_auc': array([0.710017  , 0.7138055 , 0.68766188, 0.70907462, 0.7115545 ]),\n",
       " 'train_auc': array([0.89342185, 0.89314156, 0.89691017, 0.88981106, 0.88098145]),\n",
       " 'test_recall': array([0.76  , 0.7635, 0.6745, 0.7175, 0.758 ]),\n",
       " 'train_recall': array([0.890625, 0.891125, 0.842   , 0.84125 , 0.873   ])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "rf = DecisionTreeClassifier(max_depth=12, criterion='entropy')\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'auc': 'roc_auc',\n",
    "           'recall': 'recall'}\n",
    "\n",
    "results = cross_validate(rf, X, y, cv=5, scoring=scoring, return_train_score=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:12:14.425262Z",
     "start_time": "2018-11-27T15:12:14.404548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under RoC curve: 0.7064 ± 0.0095\n",
      "Accuracy:             0.6629 ± 0.0125\n",
      "Recall:               0.7347 ± 0.0344\n"
     ]
    }
   ],
   "source": [
    "auc = results['test_auc']\n",
    "recall = results['test_recall']\n",
    "acc = results['test_acc']\n",
    "\n",
    "print(f'Area under RoC curve: {auc.mean():0.04f} ± {auc.std():0.04f}')\n",
    "print(f'Accuracy:             {acc.mean():0.04f} ± {acc.std():0.04f}')\n",
    "print(f'Recall:               {recall.mean():0.04f} ± {recall.std():0.04f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Physics\n",
    "\n",
    "Now we could test our model and our hypothesis on real observed data. This part of the analysis is the most time \n",
    "consuming in general. It also requires more data than than this notebook can handle. \n",
    "After careful analysis one can produce an image of the gamma-ray sky\n",
    "\n",
    "<img width=\"60%\" src=\"https://www.mpi-hd.mpg.de/hfm/HESS/hgps/figures/HESS_J1813m126.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Improving Classification\n",
    "\n",
    "\n",
    "### Boosting and AdaBoost\n",
    "\n",
    "Similar to the idea of combining many classifiers through bagging (like we did for the RandomForests) we now \n",
    "train many estimators in a sequential manner. In each iteration the data gets modified slightly using weights $w$\n",
    "for each sample in the training data. In the first iteration the weights are all set to $w=1$\n",
    "\n",
    "In each successive iteration the weights are updated. The samples that were incorrectly classified in the previous \n",
    "iteration get a higher weight. The weights for correctly classified samples get decreases. \n",
    "In other words: We increase the influence/importance of samples that are difficult to classify.\n",
    "\n",
    "Predictions are performed by taking a weighted average of the single predictors.\n",
    "\n",
    "The popular AdaBoost algorithms takes this a step further by optimizing the weight of each separate classifier \n",
    "in the ensemble.\n",
    "The AdaBoost ensemble combines many learners in an iterative way. The learner at iteration $m$ is:\n",
    "\n",
    "$$\n",
    " F_{m}(x)=F_{m-1}(x)+\\gamma _{m}h_{m}(x)\n",
    "$$\n",
    "\n",
    "The choice of $F_0$ is problem specific.\n",
    "\n",
    "Each weak learner produces a prediction $h(x_{m})$ for each sample in the training set. At each iteration $m$ a \n",
    "weak learner is fitted and assigned a coefficient $\\gamma_{m}$ which is found by minimizing:\n",
    "\n",
    "$$\n",
    "\\gamma_m = {\\underset {\\gamma }{\\arg \\min }} \\sum_{i}^{N}E\\bigl(F_{m-1}(x_{i})+\\gamma h(x_{i})\\bigr)\n",
    "$$\n",
    "\n",
    "where $E(F)$ is some error function and $x_i$ is the reweighted data sample.\n",
    "\n",
    "In general this method can work with any classifying method. Traditionally it is being used with very small \n",
    "decision trees. \n",
    "The weights get used to select the split points during the minimization of the loss function in each node\n",
    "\n",
    "$$\n",
    " \\underset{(X, s) \\in \\, \\mathbf{X} \\times {S}}{\\arg \\max} IG(X,Y) =   \\underset{(X, s) \\in \\, \\mathbf{X} \\times {S}}{\\arg \\max} ( H(Y) - H(Y |\\, X) ).\n",
    "$$\n",
    "\n",
    "Below we try AdaBoost on the FACT data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:49:09.247110Z",
     "start_time": "2018-11-27T15:48:58.872812Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=2),\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.5,\n",
    ")\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = ada.predict(X_test)\n",
    "y_prediction_proba = ada.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:49:10.072785Z",
     "start_time": "2018-11-27T15:49:09.249195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f700c1158eb4daca8e35b76f3bfc80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = np.array(list(ada.staged_score(X_test, y_test)))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(scores, '.')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Iteration')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T15:49:10.727863Z",
     "start_time": "2018-11-27T15:49:10.075262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be0b4abeecd4687b2c57d46735b8109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_prediction)\n",
    "auc = roc_auc_score(y_test, y_prediction_proba[:, 1])\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prediction_proba[:, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(fpr, tpr, c=thresholds)\n",
    "plt.plot(fpr, tpr, '--', color='gray', alpha=0.5)\n",
    "plt.text(0.5, 0.5, f'AuC ROC: {auc:0.03f} \\nAccuracy: {acc:0.03f}')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting \n",
    "\n",
    "Very similar to AdaBoost. Only this time we change the target label we train the classifiers for.\n",
    "\n",
    "Formulate the general problem as follows (See Wikipedia):\n",
    "\n",
    "Starts with a constant function $F_{0}(x)$ and some differentiable loss function $L$ and incrementally expands it in a greedy fashion:\n",
    "\n",
    "$$\n",
    "F_{0}(x)={\\underset {\\gamma }{\\arg \\min }}{\\sum _{i=1}^{n}{L(y_{i},\\gamma )}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "F_{m}(x)=F_{m-1}(x)+{\\underset {h_{m}\\in {\\mathcal {H}}}{\\operatorname {arg\\,min} }}\\left[{\\sum _{i=1}^{n}{L(y_{i},F_{m-1}(x_{i})+h_{m}(x_{i}))}}\\right]\n",
    "$$\n",
    "\n",
    "Finding the best $ h_{m}\\in {\\mathcal {H}}$ is computationally speaking impossible.\n",
    "If we could find the perfect $h$ however, we know that \n",
    "\n",
    "$$\n",
    "F_{m+1}(x_i)=F_{m}(x_i)+h(x_i)=y_i\n",
    "$$\n",
    "\n",
    "or, equivalently, \n",
    "\n",
    "$$\n",
    "   h(x_i)= y_i - F_{m}(x_i)\n",
    "$$\n",
    "\n",
    "Note that for the mean squared error loss $\\frac{1}{2}(y_i - F(x_i))^2$ this is equivalent to the negative \n",
    "gradient with respect to $F_i$.\n",
    "\n",
    "For a general loss function we fit $h_{m}(x)$ to the residuals, or negative gradients \n",
    "$$\n",
    " r_{i, m}=-\\left[{\\frac {\\partial L(y_{i},F(x_{i}))}{\\partial F(x_{i})}}\\right]_{F(x)=F_{m-1}(x)}\\quad {\\mbox{for }}i=1,\\ldots ,n.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Below we try it on FACT data again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T16:56:38.715276Z",
     "start_time": "2018-11-27T16:56:29.657159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3546            7.15s\n",
      "         2           1.3273            6.90s\n",
      "         3           1.3057            6.79s\n",
      "         4           1.2880            6.71s\n",
      "         5           1.2722            6.60s\n",
      "         6           1.2568            6.52s\n",
      "         7           1.2448            6.45s\n",
      "         8           1.2281            6.40s\n",
      "         9           1.2151            6.33s\n",
      "        10           1.2059            6.28s\n",
      "        20           1.1298            5.53s\n",
      "        30           1.0871            5.14s\n",
      "        40           1.0543            4.44s\n",
      "        50           1.0270            3.64s\n",
      "        60           1.0048            2.88s\n",
      "        70           0.9873            2.14s\n",
      "        80           0.9741            1.43s\n",
      "        90           0.9566            0.71s\n",
      "       100           0.9416            0.00s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "grb = GradientBoostingClassifier(\n",
    "    verbose=True,\n",
    "    n_estimators=100,\n",
    ")\n",
    "grb.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = grb.predict(X_test)\n",
    "y_prediction_proba = grb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T16:56:39.343691Z",
     "start_time": "2018-11-27T16:56:38.718176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429baeff2b5e4cca80fda599e7b276ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = [accuracy_score(y_pred, y_test) for y_pred in grb.staged_predict(X_test)]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(len(l)), l, '.')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Iteration')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T16:56:40.215880Z",
     "start_time": "2018-11-27T16:56:39.346460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832ac98d12d54b89bdcb28f4490884f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_prediction)\n",
    "auc = roc_auc_score(y_test, y_prediction_proba[:, 1])\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prediction_proba[:, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(fpr, tpr, c=thresholds)\n",
    "plt.plot(fpr, tpr, '--', color='gray', alpha=0.5)\n",
    "plt.text(0.5, 0.5, f'AuC ROC: {auc:0.03f} \\nAccuracy: {acc:0.03f}')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on gradient descent algorithms can be found in the Neural Network notebook.\n",
    "\n",
    "Let's now test our all time favorite classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T16:58:57.873659Z",
     "start_time": "2018-11-27T16:58:45.510336Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=150,  max_depth=18, criterion='entropy')\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_prediction = rf.predict(X_test)\n",
    "y_prediction_proba = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T16:58:58.442111Z",
     "start_time": "2018-11-27T16:58:57.875736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75706ec5c2248c8844436c836546293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_prediction)\n",
    "auc = roc_auc_score(y_test, y_prediction_proba[:, 1])\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prediction_proba[:, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(fpr, tpr, c=thresholds)\n",
    "plt.plot(fpr, tpr, '--', color='gray', alpha=0.5)\n",
    "plt.text(0.5, 0.5, f'AuC ROC: {auc:0.03f} \\nAccuracy: {acc:0.03f}')\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
